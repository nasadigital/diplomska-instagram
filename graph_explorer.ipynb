{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from heapq import nlargest\n",
    "from load_data import get_hashtags\n",
    "from load_data import generate_embeddings\n",
    "from load_data import load_media\n",
    "from load_data import load_users\n",
    "from load_data import prep_train_test_bert\n",
    "from load_data import train_test_bert\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "\n",
    "random.seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "Use together with path to respective file:\n",
    "- load_users to load user graph.\n",
    "- load_Media to load media data.\n",
    "- gensim.models.Word2Vec.load for embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph = load_users('../users.csv')\n",
    "# media, hashtags = load_media('../media.csv')\n",
    "model = gensim.models.Word2Vec.load('./tag2vec64dIterator.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding clustering\n",
    "Below we generate a dendogram of the hierachical clustering of the `plot_N` most common hashtags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 15]\n",
    "plot_N = 100\n",
    "most_frequent_tags = [i[1] for i in nlargest(plot_N, [\n",
    "        (model.wv.vocab[word].count, word) for word in model.wv.vocab\n",
    "])]\n",
    "linkage_method = linkage([model[word] for word in most_frequent_tags], 'average', 'cosine')\n",
    "dendrogram(linkage_method, labels=most_frequent_tags, orientation='right',\n",
    "           leaf_font_size=8., color_threshold=0.43)\n",
    "print('Clustering complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashtag similarity\n",
    "Use model.wv.similarity with two hashtags to calculate similarity of two hashtags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[\n",
    " model.wv.similarity(w1=\"instagood\",w2=\"instamood\"),\n",
    " model.wv.similarity(w1=\"christmas\",w2=\"xmas\"),\n",
    " model.wv.similarity(w1=\"rap\",w2=\"rnb\"),\n",
    " model.wv.similarity(w1=\"dad\",w2=\"father\"),\n",
    " model.wv.similarity(w1=\"netflix\",w2=\"cats\"),\n",
    " model.wv.similarity(w1=\"nofilter\",w2=\"sanfrancisco\"),\n",
    " model.wv.similarity(w1=\"instagood\",w2=\"garden\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similar hashtags\n",
    "Use model.wv.most_similar with single hashtag, for calculating similar hashtags. Set topn to N, where N is the number of similar hashtags you want to find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['#{0} - {1:.10f}'.format(i[0], i[1]) for i in model.wv.most_similar(positive=['christmas'], topn=30)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arithmetic operations\n",
    "Use model.wv.most_similar with multiple hashtags to do arithemtic operations on hashtag vectors.\n",
    "Hashtags given in negative parameter are deducted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " model.wv.most_similar(positive=['helloween', 'christmas'], negative=['pumkin'], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating post distance\n",
    "Given two image posts, you can calculate distance between them.\n",
    "Use model.wv.wmdistance with two posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = [\n",
    "'''altimqa Takie tam üèùÔ∏èüåûüåä\n",
    "#vacation #holiday #holidays #chill #chillout #fuertaventura #spain #nikon #nikonphotography #corralejo #ocean #goodday #happy #happytime #instatravel #travel #worldtraveler #traveler #adventure #adventuretime #traveling #d5500''',\n",
    "'''marianamonkey #beach #ocean #portugal #travel #europe #instapic #instagram #instadaily #beautifuldestinations #nature #landscape #photo #instafashion #photographer #view #amazing #instalike#smile #girl #hair #beachbody #bikini #fitness #instafit #sun #dress #naturalbeauty #blue #jeans''',\n",
    "'''rbariquelo #city #cwb #curitiba #curitibacool #citygram #city_explore #architecture #urbanxplore #skyline''',\n",
    "'''#parquecascavel #buildings #jardimatlantico #towers #cityscape #landscape #urban #urbanphotography #nightfall #dusk #cityphotography #streetphotography #goiania #architectureporn #arquitetura #architecturephotography #architecture #engenhariacivil #civilengineering #brazil #igersbrasil #igersgoiania'''\n",
    "]\n",
    "for i in range(len(posts)):\n",
    "    for j in range(len(posts)):\n",
    "        print('post {0} and post {1}: {2:.10f}'.format(i, j, model.wv.wmdistance(get_hashtags(posts[i], model), get_hashtags(posts[j], model)), [t for t in get_hashtags(posts[i], model) if t in get_hashtags(posts[j], model)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating embeddings and testing\n",
    "Generate embeddings using generate_embeddings. You can also do a train and test run with train_test_pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_embeddings('../mini_media.csv', './m_tag2vec64dIterator.model', threads=2)\n",
    "# train_test_hashtag2vec('../mini_media.csv', './m_dist.dat', './models/256dModelRef', 10, # N-way split\n",
    "#                     result_path='./result256dRef.txt', dim=256, check=10)\n",
    "# import cProfile\n",
    "# pr = cProfile.Profile()\n",
    "# pr.enable()\n",
    " \n",
    "prep_train_test_bert('../mini_dataset/mini_media.csv', '../mini_dataset/m_dist.dat', '../artifacts/models/768dBertModel', 10, # N-way split\n",
    "                    result_path='./result768dBert.txt', check=1, pretrained_weights='distilbert-base-uncased')\n",
    "train_test_bert('../mini_dataset/mini_media.csv', '../mini_dataset/m_dist.dat', '../artifacts/models/768dBertModel', 10, # N-way split\n",
    "                    result_path='./result768dBert.txt', check=1, pretrained_weights='distilbert-base-uncased')\n",
    "\n",
    "# pr.disable()\n",
    "# pr.print_stats(sort='time')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
